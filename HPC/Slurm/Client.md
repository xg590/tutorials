### New compute nodes   
  * Login as gateway
    ```
    ip route add 192.168.11.0/24 via 192.168.11.1 
    iptables -P FORWARD ACCEPT
    # provide internet for subnet via the internet-connected NIC $IFNAME0
    iptables -t nat -A POSTROUTING -s 192.168.0.0/16 -o $IFNAME0 -j MASQUERADE 
    ``` 
  * Assign IP addresses for compute nodes 
    ```shell
    cp /var/lib/misc/dnsmasq.leases /root/sys_conf/dnsmasq.leases
    cat /root/sys_conf/dnsmasq.leases | awk '{print $3}' | xargs -I % ping -c 1 -t 1 % 2> /dev/null && echo %

    rm /root/sys_conf/pssh_new_host_file /root/sys_conf/pssh_old_host_file /root/.ssh/known_hosts 
    cat /root/sys_conf/dnsmasq.leases | awk '{print $3}' >> /root/sys_conf/pssh_old_host_file
    cat /root/sys_conf/dnsmasq.leases | awk '{print $3}' | xargs -I % ssh-keyscan % >> /root/.ssh/known_hosts

    CNT_BGN=2
    cat << EOF > /root/sys_conf/assignIP.awk
    BEGIN { cnt = $CNT_BGN; }
    {   
        print "echo " cnt " | ssh " \$3 " tee /tmp/.cnt" ; 
        print "echo 192.168.11." cnt " >> /root/sys_conf/pssh_new_host_file" ;  
        cnt += 1 ;
    }
    EOF
    cat /root/sys_conf/dnsmasq.leases | awk -f /root/sys_conf/assignIP.awk | tee /tmp/run.sh
    bash /tmp/run.sh
  
    cat /root/sys_conf/dnsmasq.leases | awk '{print $3}' | xargs -I % ssh % cat /tmp/.cnt
    cat /root/sys_conf/dnsmasq.leases | awk '{print $3}' | xargs -I % scp /root/sys_conf/set_nic.sh %: 
    cat /root/sys_conf/dnsmasq.leases | awk '{print $3}' | xargs -I % ssh % bash set_nic.sh 

    parallel-ssh --timeout 5 -i -h /root/sys_conf/pssh_old_host_file netplan apply
    sleep 3 # let compute nodes have sometime to bring on new IP addresses. 
    ```
  * Recalculate counter
    ```shell 
    let CNT_END=$CNT_BGN+`awk 'END { print NR }' /root/sys_conf/dnsmasq.leases`-1 # do not forget minus one
    echo $CNT_BGN $CNT_END
    seq $CNT_BGN $CNT_END | xargs -I % ping -c 1 -t 1 192.168.11.%

    rm ~/.ssh/known_hosts
    cat << EOF > /etc/hosts
    127.0.0.1               localhost
    127.0.1.1               localhost
    192.168.11.1            $HOSTNAME
    192.168.11.1            login
    EOF
    seq 2 $CNT_END | xargs -I % echo "192.168.11.% node-%" >> /etc/hosts
    seq 2 $CNT_END | xargs -I % ssh-keyscan 192.168.11.%   >> /root/.ssh/known_hosts  
    seq 2 $CNT_END | xargs -I % ssh-keyscan        node-%  >> /root/.ssh/known_hosts  
    seq 2 $CNT_END | xargs -I % ssh                node-%     hostname 
    
    # The next command takes lots of time to finish. Be patient. 
    parallel-ssh -i -t 0 -h /root/sys_conf/pssh_new_host_file 'systemctl stop unattended-upgrades'
    parallel-ssh -i -t 0 -h /root/sys_conf/pssh_new_host_file 'apt purge unattended-upgrades'
    parallel-ssh -i -t 0 -h /root/sys_conf/pssh_new_host_file 'apt update -y'
    parallel-ssh -i -t 0 -h /root/sys_conf/pssh_new_host_file 'apt install -y munge libmunge2 libmunge-dev slurmd nfs-common nis'
 
    # Test the nfs-common installation
    seq 2 $CNT_END | xargs -I % scp /etc/hosts node-%:/etc/hosts 
    seq 2 $CNT_END | xargs -I % ssh node-% 'hostname ; showmount -e login'
    ```
  * NFS Client
    ```shell
    parallel-ssh -i -t 0 -h /root/sys_conf/pssh_new_host_file 'mount -t nfs login:/home /home'
    #seq $CNT_BGN $CNT_END| xargs -I % ssh node-% 'echo "login:/home /home nfs defaults 0 0" >> /tmp/etc_fstab'
    ```
  * NIS client
    ```shell 
    seq $CNT_BGN $CNT_END | xargs -I % scp /etc/{defaultdomain,yp.conf,nsswitch.conf} node-%:/etc/ 
    seq $CNT_BGN $CNT_END | xargs -I % ssh node-% systemctl restart rpcbind nscd ypbind  
    seq $CNT_BGN $CNT_END | xargs -I % ssh node-% ypwhich # test the NIS
    seq $CNT_BGN $CNT_END | xargs -I % ssh node-% ypcat passwd # test again and see the populated identity

    seq $CNT_BGN $CNT_END | xargs -I % ssh node-% systemctl enable rpcbind nscd ypbind 
    ```
  * Munge Client
    ```shell
    seq $CNT_BGN $CNT_END | xargs -I % scp /etc/munge/munge.key node-%:/etc/munge/munge.key 
    parallel-ssh -i -h /root/sys_conf/pssh_new_host_file 'systemctl restart munge'
    for i in `seq $CNT_BGN $CNT_END`; do munge -n | ssh node-$i unmunge; done # test munge to see if it works well between login node and node0

    parallel-ssh -i -h /root/sys_conf/pssh_new_host_file 'systemctl enable munge'
    ```
  * Slurm Client
    * After added new compute nodes 
      * Change and sync /etc/slurm/slurm.conf
    ```shell
    cat << EOF > /etc/slurm/slurm.conf
    # slurm.conf file can be generated by https://slurm.schedmd.com/configurator.html
    # also see https://github.com/SchedMD/slurm/blob/master/etc/slurm.conf.example
    AuthType=auth/munge
    ClusterName=perfect
    SlurmctldHost=$HOSTNAME
    MpiDefault=none
    ReturnToService=1
    SlurmctldPidFile=/var/run/slurmctld.pid
    SlurmctldPort=6817
    SlurmdPidFile=/var/run/slurmd.pid
    SlurmdPort=6818
    SlurmdSpoolDir=/var/spool/slurmd
    SlurmUser=slurm
    StateSaveLocation=/var/spool/slurmctld
    SwitchType=switch/none
    ProctrackType=proctrack/cgroup
    TaskPlugin=task/affinity
    
    # TIMERS
    InactiveLimit=0
    KillWait=30
    MinJobAge=300
    SlurmctldTimeout=120
    SlurmdTimeout=300
    Waittime=0
    
    # SCHEDULING
    SchedulerType=sched/backfill
    SelectType=select/cons_tres
    SelectTypeParameters=CR_Core
    
    # LOGGING AND ACCOUNTING
    AccountingStorageType=accounting_storage/none
    JobCompType=jobcomp/none
    JobAcctGatherType=jobacct_gather/none
    JobAcctGatherFrequency=30
    SlurmctldDebug=info
    SlurmctldLogFile=/var/log/slurmctld.log
    SlurmdDebug=info
    SlurmdLogFile=/var/log/slurmd.log
 
    # Node Conf 
    NodeName=$HOSTNAME,node-[2-$CNT_END] CPUs=28 State=UNKNOWN  
    
    # Partition Conf
    PartitionName=$HOSTNAME Nodes=$HOSTNAME Default=YES MaxTime=INFINITE State=UP
    PartitionName=cmpt Nodes=node-[2-$CNT_END] Default=YES MaxTime=INFINITE State=UP
    EOF
    tail /etc/slurm/slurm.conf
    ```
      * Stop slurmctld  
      * Restart all slurmd processes  
      * Start slurmctld
    ```
    seq 2 $CNT_END | xargs -I % scp /etc/slurm/{slurm.conf,cgroup.conf} node-%:/etc/slurm/

    systemctl stop  slurmctld slurmd 
    seq 2 $CNT_END | xargs -I % ssh node-% systemctl restart slurmd 
    systemctl start slurmctld slurmd 

    srun --nodelist=node-$CNT_END --chdir /tmp --pty /bin/bash

    parallel-ssh -i -h /root/sys_conf/pssh_new_host_file 'systemctl enable slurmd'
    ```