{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rewrite of https://github.com/harvardnlp/annotated-transformer/blob/master/The%20Annotated%20Transformer.ipynb\n",
    "# pip install torch matplotlib spacy torchtext seaborn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-08T12:29:25.316497Z",
     "start_time": "2022-04-08T12:29:24.879891Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch, copy, pdb, math\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-08T12:29:25.319987Z",
     "start_time": "2022-04-08T12:29:25.317608Z"
    }
   },
   "outputs": [],
   "source": [
    "N = 2 # number of encoder or decoder stacks \n",
    "h = 8 # heards in parallel\n",
    "d_model = 512 # dimensions \n",
    "dropout_rate = 0.1\n",
    "d_ff = 2048\n",
    "\n",
    "vocab_size_src  = 51\n",
    "vocab_size_tgt  = 51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-08T12:29:25.415280Z",
     "start_time": "2022-04-08T12:29:25.321017Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class Embedding(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super(Embedding, self).__init__() \n",
    "        self.emb = nn.Embedding(vocab_size, d_model) # https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.emb(x) * math.sqrt(d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-08T12:29:25.490864Z",
     "start_time": "2022-04-08T12:29:25.418583Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def PositionalEncoding(): \n",
    "    # Implement the PE function.\n",
    "    # Compute the positional encodings once in log space.\n",
    "    max_len = 999\n",
    "    position = torch.arange(0, max_len).unsqueeze(1)\n",
    "    div_term = torch.exp(torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model))\n",
    "    pe = torch.zeros(max_len, d_model, requires_grad=False)\n",
    "    pe[:, 0::2] = torch.sin(position * div_term)\n",
    "    pe[:, 1::2] = torch.cos(position * div_term)\n",
    "    return pe.unsqueeze(0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-08T12:29:25.559906Z",
     "start_time": "2022-04-08T12:29:25.501962Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class MultiHeadedAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"Take in model size and number of heads.\"\n",
    "        super(MultiHeadedAttention, self).__init__()\n",
    "        assert d_model % h == 0\n",
    "        # We assume d_v always equals d_k\n",
    "        self.d_k     = d_model // h\n",
    "        self.h       = h\n",
    "        self.l1      = nn.Linear(d_model, d_model) \n",
    "        self.l2      = nn.Linear(d_model, d_model) \n",
    "        self.l3      = nn.Linear(d_model, d_model) \n",
    "        self.l4      = nn.Linear(d_model, d_model)  \n",
    "        \n",
    "    def attention(self, Q, K, V, mask=None):\n",
    "        \"Compute 'Scaled Dot Product Attention'\"\n",
    "        d_k = Q.size(-1)\n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(d_k)\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, -1e9)\n",
    "        weights = F.softmax(scores, dim = -1) \n",
    "        x = torch.matmul(weights, V) \n",
    "        return x\n",
    "\n",
    "    def forward(self, Q, K, V, mask=None):\n",
    "        \"Implements Figure 2\"\n",
    "        if mask is not None:\n",
    "            # Same mask applied to all h heads.\n",
    "            mask = mask.unsqueeze(1)\n",
    "        nbatches = Q.size(0) \n",
    "        # 1) Do all the linear projections in batch from d_model => h x d_k\n",
    "        Q = self.l1(Q).view(nbatches, -1, self.h, self.d_k).transpose(1, 2)\n",
    "        K = self.l2(K).view(nbatches, -1, self.h, self.d_k).transpose(1, 2)\n",
    "        V = self.l3(V).view(nbatches, -1, self.h, self.d_k).transpose(1, 2)\n",
    "         \n",
    "        # 2) Apply attention on all the projected vectors in batch. \n",
    "        x = self.attention(Q, K, V, mask=mask) \n",
    "        \n",
    "        # 3) \"Concat\" using a view and apply a final linear.\n",
    "        x = x.transpose(1, 2).contiguous().view(nbatches, -1, d_model)\n",
    "        x = self.l4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-08T12:29:25.651351Z",
     "start_time": "2022-04-08T12:29:25.564198Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    \"Implements FFN equation.\"\n",
    "    def __init__(self):\n",
    "        super(FeedForward, self).__init__()\n",
    "        self.l1 = nn.Linear(d_model, d_ff)\n",
    "        self.l2 = nn.Linear(d_ff, d_model) \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.l1(x)\n",
    "        x = F.relu(x) \n",
    "        x = self.l2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-08T12:29:25.736297Z",
     "start_time": "2022-04-08T12:29:25.656079Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    \"Encoder is made up of self-attn and feed forward (defined below)\"\n",
    "    def __init__(self):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.mha = MultiHeadedAttention()\n",
    "        self.ff = FeedForward( ) \n",
    "        self.norm1 = nn.LayerNorm(d_model, eps=1e-6)\n",
    "        self.norm2 = nn.LayerNorm(d_model, eps=1e-6) \n",
    "        self.dropout1 = nn.Dropout(dropout_rate)\n",
    "        self.dropout2 = nn.Dropout(dropout_rate)\n",
    " \n",
    "    def forward(self, x):\n",
    "        \"Follow Figure 1 (left) for connections.\"\n",
    "        x = x + self.dropout1(self.mha(self.norm1(x), self.norm1(x), self.norm1(x)))  \n",
    "        x = x + self.dropout2(self.ff (self.norm2(x)))  \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-08T12:29:25.800772Z",
     "start_time": "2022-04-08T12:29:25.741164Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    \"Decoder is made of self-attn, src-attn, and feed forward (defined below)\"\n",
    "    def __init__(self):\n",
    "        super(DecoderLayer, self).__init__() \n",
    "        self.mmha     = MultiHeadedAttention()\n",
    "        self.mha      = MultiHeadedAttention() \n",
    "        self.ff       = FeedForward( ) \n",
    "        self.norm1    = nn.LayerNorm(d_model, eps=1e-6)\n",
    "        self.norm2    = nn.LayerNorm(d_model, eps=1e-6)\n",
    "        self.norm3    = nn.LayerNorm(d_model, eps=1e-6) \n",
    "        self.dropout1 = nn.Dropout(dropout_rate)\n",
    "        self.dropout2 = nn.Dropout(dropout_rate)\n",
    "        self.dropout3 = nn.Dropout(dropout_rate)  \n",
    " \n",
    "    def forward(self, x, memory, tgt_mask):\n",
    "        \"Follow Figure 1 (right) for connections.\" \n",
    "        x = x + self.dropout1(self.mmha(self.norm1(x), self.norm1(x), self.norm1(x), tgt_mask) )  \n",
    "        x = x + self.dropout2(self.mha (self.norm2(x), memory, memory))    \n",
    "        x = x + self.dropout3(self.ff  (self.norm3(x)))    \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-08T12:29:25.873930Z",
     "start_time": "2022-04-08T12:29:25.805494Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    \"Define standard linear + softmax generation step.\"\n",
    "    def __init__(self, d_model, vocab):\n",
    "        super(Generator, self).__init__()\n",
    "        self.proj = nn.Linear(d_model, vocab)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.log_softmax(self.proj(x), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-08T12:29:25.964539Z",
     "start_time": "2022-04-08T12:29:25.878690Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    \"\"\"\n",
    "    A standard Encoder-Decoder architecture. Base for this and many \n",
    "    other models.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(Transformer, self).__init__()\n",
    "          \n",
    "        self.src_embed     = Embedding(vocab_size_src)\n",
    "        self.pe            = PositionalEncoding()\n",
    "        self.encoderLayers = nn.ModuleList([copy.deepcopy(EncoderLayer()) for _ in range(N)]) \n",
    "        self.norm1         = nn.LayerNorm(d_model, eps=1e-6)\n",
    "        \n",
    "        self.tgt_embed     = Embedding(vocab_size_tgt)\n",
    "        self.decoderLayers = nn.ModuleList([copy.deepcopy(DecoderLayer()) for _ in range(N)])  \n",
    "        self.generator     = Generator(d_model, vocab_size_tgt)\n",
    "        self.norm2         = nn.LayerNorm(d_model, eps=1e-6)\n",
    "        \n",
    "    def forward(self, src, tgt, tgt_mask):\n",
    "        \"Take in and process masked src and target sequences.\"\n",
    "        memory = self.norm1(self.encode(src))\n",
    "        tgt    = self.norm2(self.decode(memory, tgt, tgt_mask))\n",
    "        return tgt \n",
    "    \n",
    "    def encode(self, src):\n",
    "        src = self.src_embed(src) \n",
    "        src = src + self.pe[:, :src.size(1)]  \n",
    "        for layer in self.encoderLayers:\n",
    "            src = layer(src) \n",
    "        memory = src\n",
    "        return memory\n",
    "    \n",
    "    def decode(self, memory, tgt, tgt_mask):\n",
    "        tgt = self.tgt_embed(tgt)\n",
    "        tgt = tgt + self.pe[:, :tgt.size(1)]   \n",
    "        for layer in self.decoderLayers:\n",
    "            tgt = layer(tgt, memory, tgt_mask) \n",
    "        return tgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-08T12:29:26.040929Z",
     "start_time": "2022-04-08T12:29:25.972646Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_model(src_vocab, tgt_vocab, N=6, \n",
    "               d_model=512, d_ff=2048, h=8, dropout=0.1):\n",
    "    \"Helper: Construct a model from hyperparameters.\"\n",
    "    model = Transformer(\n",
    "        )\n",
    "    \n",
    "    # This was important from their code. \n",
    "    # Initialize parameters with Glorot / fan_avg.\n",
    "    for p in model.parameters():\n",
    "        if p.dim() > 1:\n",
    "            nn.init.xavier_uniform_(p)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-08T12:29:26.127761Z",
     "start_time": "2022-04-08T12:29:26.045496Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def subsequent_mask(size):\n",
    "    attn_shape = (1, size, size) \n",
    "    return torch.triu(torch.ones(attn_shape, dtype=int), diagonal=1) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-08T12:29:26.191550Z",
     "start_time": "2022-04-08T12:29:26.132486Z"
    }
   },
   "outputs": [],
   "source": [
    "class Batch:\n",
    "    \"Object for holding a batch of data with mask during training.\"\n",
    "    def __init__(self, src, trg=None, pad=0):\n",
    "        self.src = src\n",
    "        self.src_mask = (src != pad).unsqueeze(-2)\n",
    "        if trg is not None:\n",
    "            self.trg = trg[:, :-1]\n",
    "            self.trg_y = trg[:, 1:]\n",
    "            self.trg_mask = self.make_std_mask(self.trg, pad)\n",
    "            self.ntokens = (self.trg_y != pad).data.sum()\n",
    "     \n",
    "    def make_std_mask(self, tgt, pad):\n",
    "        \"Create a mask to hide padding and future words.\"\n",
    "        tgt_mask = (tgt != pad).unsqueeze(-2)\n",
    "        tgt_mask = tgt_mask & subsequent_mask(tgt.size(-1)) \n",
    "        return tgt_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-08T12:29:26.324116Z",
     "start_time": "2022-04-08T12:29:26.196282Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_epoch(data_iter, model, loss_compute):\n",
    "    \"Standard Training and Logging Function\" \n",
    "    total_tokens = 0\n",
    "    total_loss = 0\n",
    "    tokens = 0\n",
    "    for i, batch in enumerate(data_iter):\n",
    "        out = model.forward(batch.src, batch.trg, batch.trg_mask)\n",
    "        loss = loss_compute(out, batch.trg_y, batch.ntokens)\n",
    "        total_loss += loss\n",
    "        total_tokens += batch.ntokens\n",
    "        tokens += batch.ntokens\n",
    "        if i % 50 == 1: \n",
    "            # print(\"Epoch Step: %d Loss: %f Tokens per Sec: %f\" % (i, loss / batch.ntokens, tokens / elapsed)) \n",
    "            tokens = 0\n",
    "    return total_loss / total_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-08T12:29:26.391343Z",
     "start_time": "2022-04-08T12:29:26.328749Z"
    }
   },
   "outputs": [],
   "source": [
    "global max_src_in_batch, max_tgt_in_batch\n",
    "def batch_size_fn(new, count, sofar):\n",
    "    \"Keep augmenting batch and calculate total number of tokens + padding.\"\n",
    "    global max_src_in_batch, max_tgt_in_batch\n",
    "    if count == 1:\n",
    "        max_src_in_batch = 0\n",
    "        max_tgt_in_batch = 0\n",
    "    max_src_in_batch = max(max_src_in_batch,  len(new.src))\n",
    "    max_tgt_in_batch = max(max_tgt_in_batch,  len(new.trg) + 2)\n",
    "    src_elements = count * max_src_in_batch\n",
    "    tgt_elements = count * max_tgt_in_batch\n",
    "    return max(src_elements, tgt_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-08T12:29:26.480237Z",
     "start_time": "2022-04-08T12:29:26.395847Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class NoamOpt:\n",
    "    \"Optim wrapper that implements rate.\"\n",
    "    def __init__(self, model_size, factor, warmup, optimizer):\n",
    "        self.optimizer = optimizer\n",
    "        self._step = 0\n",
    "        self.warmup = warmup\n",
    "        self.factor = factor\n",
    "        self.model_size = d_model\n",
    "        self._rate = 0\n",
    "        \n",
    "    def step(self):\n",
    "        \"Update parameters and rate\"\n",
    "        self._step += 1\n",
    "        rate = self.rate()\n",
    "        for p in self.optimizer.param_groups:\n",
    "            p['lr'] = rate\n",
    "        self._rate = rate\n",
    "        self.optimizer.step()\n",
    "        \n",
    "    def rate(self, step = None):\n",
    "        \"Implement `lrate` above\"\n",
    "        if step is None:\n",
    "            step = self._step\n",
    "        return self.factor * (self.model_size ** (-0.5) * min(step ** (-0.5), step * self.warmup ** (-1.5))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-08T12:29:26.547532Z",
     "start_time": "2022-04-08T12:29:26.485103Z"
    }
   },
   "outputs": [],
   "source": [
    "def data_gen(V, batch, nbatches): \n",
    "    \"Generate random data for a src-tgt copy task.\"\n",
    "    for i in range(nbatches): \n",
    "        src = torch.randint(1, V, size=(batch, V), requires_grad=False)\n",
    "        src[:, 0] = 1\n",
    "        tgt = copy.deepcopy(src)\n",
    "        yield Batch(src, tgt, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-08T12:29:26.633054Z",
     "start_time": "2022-04-08T12:29:26.550884Z"
    }
   },
   "outputs": [],
   "source": [
    "class SimpleLossCompute:\n",
    "    \"A simple loss compute and train function.\"\n",
    "    def __init__(self, generator, criterion, opt=None):\n",
    "        self.generator = generator\n",
    "        self.criterion = criterion\n",
    "        self.opt = opt\n",
    "        \n",
    "    def __call__(self, x, y, norm):\n",
    "        x = self.generator(x)\n",
    "        loss  = self.criterion(x.contiguous().view(-1, x.size(-1)), y.contiguous().view(-1)) \n",
    "        loss /= norm\n",
    "        loss.backward()\n",
    "        if self.opt is not None:\n",
    "            self.opt.step()\n",
    "            self.opt.optimizer.zero_grad() \n",
    "        return loss.data * norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-08T13:44:33.556757Z",
     "start_time": "2022-04-08T13:32:39.650377Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : tensor(0.0027)\n",
      "2 : tensor(0.0026)\n",
      "3 : tensor(0.0026)\n",
      "4 : tensor(0.0024)\n",
      "5 : tensor(0.0022)\n",
      "6 : tensor(0.0017)\n",
      "7 : tensor(0.0013)\n",
      "8 : tensor(0.0008)\n",
      "9 : tensor(0.0003)\n",
      "10 : tensor(0.0002)\n",
      "11 : tensor(8.3170e-05)\n",
      "12 : tensor(4.8422e-05)\n",
      "13 : tensor(4.7529e-05)\n",
      "14 : tensor(7.6590e-05)\n",
      "15 : tensor(8.1474e-05)\n",
      "16 : tensor(6.4091e-05)\n",
      "17 : tensor(3.7960e-05)\n",
      "18 : tensor(3.6851e-05)\n",
      "19 : tensor(5.2938e-05)\n",
      "20 : tensor(3.7670e-05)\n",
      "21 : tensor(7.1067e-05)\n",
      "22 : tensor(4.2804e-05)\n",
      "23 : tensor(2.3188e-05)\n",
      "24 : tensor(2.7754e-05)\n",
      "25 : tensor(4.1535e-05)\n",
      "26 : tensor(2.3626e-05)\n",
      "27 : tensor(2.0970e-05)\n",
      "28 : tensor(1.6799e-05)\n",
      "29 : tensor(2.6592e-05)\n",
      "30 : tensor(1.8358e-05)\n",
      "31 : tensor(2.3255e-05)\n",
      "32 : tensor(2.2536e-05)\n",
      "33 : tensor(1.1023e-05)\n",
      "34 : tensor(2.0560e-05)\n",
      "35 : tensor(1.6535e-05)\n",
      "36 : tensor(1.6381e-05)\n",
      "37 : tensor(1.6006e-05)\n",
      "38 : tensor(1.6477e-05)\n",
      "39 : tensor(2.2869e-05)\n",
      "40 : tensor(1.4038e-05)\n",
      "41 : tensor(1.3275e-05)\n",
      "42 : tensor(1.0311e-05)\n",
      "43 : tensor(1.1329e-05)\n",
      "44 : tensor(1.2837e-05)\n",
      "45 : tensor(1.3179e-05)\n",
      "46 : tensor(3.4831e-06)\n",
      "!!!!!!!!!!!!!!!!!!!!! tensor(49)\n"
     ]
    }
   ],
   "source": [
    "# Train the simple copy task.\n",
    "V = 51\n",
    "criterion = nn.CrossEntropyLoss()#LabelSmoothing(size=V, padding_idx=0, smoothing=0.0)\n",
    "for nth_test in range(1):\n",
    "    model = make_model(V, V, N=2)\n",
    "    model_opt = NoamOpt(d_model, \n",
    "                        1, \n",
    "                        400, \n",
    "                        torch.optim.Adam(model.parameters(), \n",
    "                                         lr=0, \n",
    "                                         betas=(0.9, 0.98), \n",
    "                                         eps=1e-9\n",
    "                                        )\n",
    "                       )\n",
    "    #model_opt = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "    for epoch in range(50):\n",
    "        model.train()\n",
    "        run_epoch(data_gen(V, 30, 20), model, SimpleLossCompute(model.generator, criterion, model_opt))\n",
    "        model.eval()\n",
    "        check = run_epoch(data_gen(V, 30, 5), model, SimpleLossCompute(model.generator, criterion, None))\n",
    "        print(epoch+1, ':',check)\n",
    "        if check < 0.00001:\n",
    "            break\n",
    "    \n",
    "    def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
    "        #pdb.set_trace()\n",
    "        memory = model.encode(src)\n",
    "        ys = torch.ones(1, 1).fill_(start_symbol).type_as(src.data)\n",
    "        for i in range(max_len-1):\n",
    "            out = model.decode(memory, ys, subsequent_mask(ys.size(1))) \n",
    "            prob = model.generator(out[:, -1])\n",
    "            _, next_word = torch.max(prob, dim = 1)\n",
    "            next_word = next_word.data[0]\n",
    "            ys = torch.cat([ys, torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=1)\n",
    "        return ys\n",
    "    \n",
    "    model.eval()\n",
    "    t = 50\n",
    "    src = torch.arange(1, t+1).unsqueeze(0)\n",
    "    src_mask = torch.ones(1, 1, t) \n",
    "    pred = greedy_decode(model, src, src_mask, max_len=t, start_symbol=1)\n",
    "    #print(pred)\n",
    "    print('!!!!!!!!!!!!!!!!!!!!!', sum([i==j for i,j in zip(pred[0],range(1,51))]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
